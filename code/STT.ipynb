{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1ZP3QbTi2ddT6n5izWeozqesLPIVicyjC",
      "authorship_tag": "ABX9TyNHjm2fHPriDm+sHl6vjeOX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/catundchat/LLM_report/blob/main/STT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "语音识别代码示例，使用方法：\n",
        "1. choose appropriate pretrained model and tokenizer\n",
        "2. load audio file\n",
        "3. run the demo to generate transcription\n",
        "4. compare transcription with groundtruth"
      ],
      "metadata": {
        "id": "ov8jefZxlVeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install librosa\n",
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ7f6svjG8Jt",
        "outputId": "bae4985c-d582-4365-c30d-58ca0bd23906"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.0.post2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.5)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.3)\n",
            "Collecting rapidfuzz==2.13.7\n",
            "  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.0.1 rapidfuzz-2.13.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMhLeoCfP7Bs",
        "outputId": "e2eaac32-269f-4fa8-d610-198297feddf3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  9 10:15:15 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import torch\n",
        "import numpy as np\n",
        "import re\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "from jiwer import wer, cer\n",
        "\n",
        "# 定义编辑距离函数\n",
        "def edit_distance(s1, s2):\n",
        "    m, n = len(s1), len(s2)\n",
        "    dp = np.zeros((m+1, n+1), dtype=int)\n",
        "    for i in range(m+1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n+1):\n",
        "        dp[0][j] = j\n",
        "    for i in range(1, m+1):\n",
        "        for j in range(1, n+1):\n",
        "            if s1[i-1] == s2[j-1]:\n",
        "                dp[i][j] = dp[i-1][j-1]\n",
        "            else:\n",
        "                dp[i][j] = min(dp[i-1][j-1], dp[i-1][j], dp[i][j-1]) + 1\n",
        "    return dp[m][n]\n",
        "\n",
        "# 定义计算字符错误率CER的函数\n",
        "def cer(ground_truth, transcription):\n",
        "    distance = edit_distance(ground_truth, transcription)\n",
        "    return distance / len(ground_truth)\n",
        "\n",
        "# 定义计算准确率的函数\n",
        "def accuracy(ground_truth, transcription):\n",
        "    correct_chars = sum(1 for gt_char, tr_char in zip(ground_truth, transcription) if gt_char == tr_char)\n",
        "    return correct_chars / len(ground_truth)\n",
        "\n",
        "# 去除中文字段里的标点符号\n",
        "def remove_punctuation(text):\n",
        "    pattern = re.compile(r\"[\\u3000-\\u303f\\uff00-\\uffef]|[.,!?;]\")\n",
        "    return re.sub(pattern, \"\", text)\n",
        "\n",
        "try:\n",
        "    # 下载在中文文本上微调后的预训练Wav2Vec2模型，根据需要更改模型，这里推荐wbbbbb/wav2vec2-large-chinese-zh-cn\n",
        "    processor = Wav2Vec2Processor.from_pretrained(\"wbbbbb/wav2vec2-large-chinese-zh-cn\")\n",
        "    model = Wav2Vec2ForCTC.from_pretrained(\"wbbbbb/wav2vec2-large-chinese-zh-cn\")\n",
        "\n",
        "    # 载入音频文件，根据需要修改路径！\n",
        "    audio_file = \"/content/drive/MyDrive/Colab Notebooks/Juxue_Tech/data/P290_convert.wav\"\n",
        "    speech, _ = librosa.load(audio_file, sr=16000, mono=True)\n",
        "\n",
        "    # 预处理音频，该模型设置采样频率必须必须为16kHz！\n",
        "    input_values = processor(speech, return_tensors=\"pt\", padding=True, sampling_rate=16000).input_values\n",
        "\n",
        "    # 使用 Wav2Vec2 模型进行推理\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "\n",
        "    # 得到预测的文字\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = processor.decode(predicted_ids[0])\n",
        "\n",
        "    # print(\"Transcription:\", transcription)\n",
        "    print(f\"Transcription: {transcription}\")\n",
        "  \n",
        "    # 提供音频的实际文本\n",
        "    ground_truth = \"信息技术部门中机器学习的主要应用之一是向潜在用户或客户推荐项目。这可以分为两种主要的应用：在线广告和项目建议（通常这些建议的目的仍是为了销售产品）。两者都依赖于预测用户和项目的关联，一旦向该用户展示了广告或推荐了该产品，推荐系统要么预测一些行为的概率。\"\n",
        "    ground_truth_punc = remove_punctuation(ground_truth)\n",
        "    # print(f\"groundtruth without punctuation: {ground_truth_punc}\")\n",
        "\n",
        "    # 计算 Accuracy 和 CER，对于中文文本来说，字错误率CER更能反映中文语音识别效果好坏\n",
        "    acc = accuracy(ground_truth, transcription)\n",
        "    acc_punc = accuracy(ground_truth_punc, transcription)\n",
        "    CER = cer(ground_truth, transcription)\n",
        "    CER_punc = cer(ground_truth_punc, transcription)\n",
        "\n",
        "    # 输出计算结果\n",
        "    print(f\"Accuracy without punctuation: {acc_punc:.4f}, Accuracy: {acc:.4f} \")\n",
        "    print(f\"CER without punctuation: {CER_punc:.4f}, CER: {CER:.4f}\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"An error occurred:\", e)\n"
      ],
      "metadata": {
        "id": "CgUnHmjAI9-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "723e9f2d-3dd3-49a4-c0cf-75aa3d75706b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription: 信息技术部门中机器学习的主要运用之一是向潜在用户或客户推荐项目这可以分为两种主要的应用在线广告和项目建议通常这些建议的目的仍然是为了销售产品两者都依赖于预测用户和项目之间的观联一旦向该用户展示的广告和推荐的该产品推荐系统要么预测一些行为的概率\n",
            "Accuracy without punctuation: 0.5169, Accuracy: 0.2381 \n",
            "CER without punctuation: 0.0678, CER: 0.1270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "模型1：wbbbbb/wav2vec2-large-chinese-zh-cn\n",
        "\n",
        "Transcription: 信息技术部门中机器学习的主要运用之一是向潜在用户或客户推荐项目这可以分为两种主要的应用在线广告和项目建议通常这些建议的目的仍然是为了销售产品两者都依赖于预测用户和项目之间的观联一旦向该用户展示的广告和推荐的该产品推荐系统要么预测一些行为的概率\n",
        "\n",
        "Accuracy without punctuation: 0.5169, Accuracy: 0.2381 \n",
        "\n",
        "CER without punctuation: 0.0678, CER: 0.1270"
      ],
      "metadata": {
        "id": "HhEPmjfrercL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "模型2：jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn\n",
        "\n",
        "Transcription: 新息技术部门中技器学习的主要运用之一是项潜在用户或客户推荐项目这可以分为两种主要的应用在先广告和项目建议通常这些建议的目的仍然是为了销售产品两者都依赖于预测用户和项目之金内观联一但项该用户展示的广告和推荐的该产品推荐系统要木预测些行为的概率\n",
        "\n",
        "Accuracy without punctuation: 0.4831, Accuracy: 0.2143 \n",
        "\n",
        "CER without punctuation: 0.1441, CER: 0.1984"
      ],
      "metadata": {
        "id": "0YYpMLwcTy-Y"
      }
    }
  ]
}
